# My First App — Learning Guide

A step-by-step walkthrough of every component in this Task Manager API project.

---

## Step 1: `package.json`

This is the project's manifest — the first file created in any Node.js project. It tells Node (and npm) everything about your app.

Key sections:

- **`name` / `version` / `description`** — basic identity of the project

- **`scripts`** — shortcuts you run with `npm run <name>`:
  - `dev` — starts the server in watch mode (auto-restarts on file changes)
  - `build` — compiles TypeScript to JavaScript
  - `start` — runs the compiled app
  - `test` — runs tests once
  - `lint` — checks code style

- **`dependencies`** — packages needed at runtime:
  - `express` — the web framework
  - `cors` — allows cross-origin requests
  - `uuid` — generates unique IDs for tasks

- **`devDependencies`** — packages needed only during development:
  - `typescript` + `@types/*` — type system
  - `vitest` + `supertest` — testing tools
  - `eslint` — code linting
  - `tsx` — runs TypeScript directly without compiling first

---

## Step 2: `tsconfig.json`

This tells the TypeScript compiler how to behave. Think of it as the "rules" for converting your `.ts` files into `.js`.

Key settings:

- **`target: "ES2022"`** — what JavaScript version to compile down to. ES2022 is modern and supports features like `async/await` natively
- **`module: "commonjs"`** — the output uses `require()` style imports (Node.js standard)
- **`strict: true`** — enables all strict type-checking rules. Catches more bugs at compile time
- **`outDir: "./dist"`** — compiled JavaScript goes into the `dist/` folder
- **`rootDir: "./src"`** — source TypeScript lives in `src/`
- **`esModuleInterop: true`** — lets you use `import express from "express"` instead of the clunkier `import * as express` syntax
- **`sourceMap: true`** — generates `.map` files so error stack traces point to your `.ts` files, not the compiled `.js`
- **`include: ["src/**/*"]`** — only compile files inside `src/`
- **`exclude: ["node_modules", "dist", "tests"]`** — skip these folders during compilation

---

## Step 3: `src/models/task.ts`

This file defines the **shape of your data** using TypeScript interfaces. No logic here — just structure.

Three interfaces:

- **`Task`** — the full task object:
  - `id` — unique identifier (string, generated by UUID)
  - `title` — the task name
  - `description` — optional details
  - `completed` — done or not (boolean)
  - `createdAt` / `updatedAt` — timestamps as ISO strings

- **`CreateTaskInput`** — what a user sends when creating a task:
  - `title` — required
  - `description` — optional
  - Notice: no `id`, `completed`, or timestamps — those are set automatically by the service

- **`UpdateTaskInput`** — what a user sends when editing a task:
  - `title?`, `description?`, `completed?` — all optional
  - The `?` means you can update just one field without touching the others

The key idea: **separate what the user sends from what the system stores**. A `Task` has 6 fields, but you only expose 1-2 for creation.

### Q&A: "In a real app these would map to database tables — is it not part of the current project?"

Right now this project uses an **in-memory store** — a JavaScript `Map` object inside `src/services/taskService.ts`. That means:
- Tasks are stored in memory (RAM) while the server is running
- **When you stop the server, all data is lost**
- No database is involved

This works fine for learning and prototyping, but in a production app you'd connect to a real database (like PostgreSQL, MongoDB, etc.) and each interface would map to a table/collection. For example, the `Task` interface would become a `tasks` table with columns for `id`, `title`, `description`, `completed`, `created_at`, `updated_at`.

Tools like **Prisma** or **TypeORM** (mentioned in the comment in that file) help bridge TypeScript interfaces to database tables. But for this project the in-memory `Map` keeps things simple so you can focus on learning the architecture without database setup.

---

## Step 4: `src/services/taskService.ts`

This is the **business logic layer** — where the actual work happens. It handles creating, reading, updating, and deleting tasks without knowing anything about HTTP.

Key parts:

- **`let tasks: Map<string, Task>`** — the in-memory store. A `Map` where the key is the task ID and the value is the `Task` object

- **`getAllTasks()`** — converts the Map values into an array and returns them

- **`getTaskById(id)`** — looks up a single task by its ID. Returns `undefined` if not found

- **`createTask(input)`** — the most interesting one:
  - Validates that a title exists (throws an error if not)
  - Trims whitespace from title and description
  - Auto-generates an `id` using UUID
  - Sets `completed` to `false`
  - Sets `createdAt` and `updatedAt` to the current time
  - Stores it in the Map and returns it

- **`updateTask(id, input)`** — finds the existing task, merges in only the fields you provided (using the spread `...` operator), updates the `updatedAt` timestamp

- **`deleteTask(id)`** — removes from the Map. Returns `true` if it existed, `false` if not

- **`clearAllTasks()`** — resets the store. Exists purely for tests so each test starts with a clean slate

The key design principle: **this layer has zero knowledge of HTTP**. No `req`, `res`, or status codes. That makes it easy to test in isolation.

---

## Step 5: `src/routes/tasks.ts`

This is the **HTTP layer** — it translates web requests into service calls and service results into web responses. It should be **thin** — no business logic here.

Five endpoints on a `Router`:

- **`GET /`** (maps to `/api/tasks`) — calls `getAllTasks()`, returns the array as JSON with status 200
- **`GET /:id`** (maps to `/api/tasks/:id`) — calls `getTaskById()`. If found, returns the task. If not, returns `404` with `{ error: "Task not found" }`
- **`POST /`** — takes `req.body`, passes it to `createTask()`. Returns `201` (created) on success. If the service throws (e.g., missing title), catches the error and returns `400` (bad request)
- **`PATCH /:id`** — takes `req.body` and the ID from the URL, passes both to `updateTask()`. Returns the updated task. If not found, returns `404`
- **`DELETE /:id`** — calls `deleteTask()`. If it existed, returns `204` (no content — success but nothing to send back). If not, returns `404`

Notice the pattern in every handler:
1. Extract data from the request (`req.params`, `req.body`)
2. Call the service
3. Send back a response with the right status code

The route never decides *how* to create or validate a task — that's the service's job. The route only decides *what HTTP status code* to return.

---

## Step 6: `src/middleware/errorHandler.ts`

This is a **safety net** — it catches any unhandled errors that slip through your route handlers.

How it works:

- Express recognizes it as an error handler because it has **4 parameters**: `(err, req, res, next)`. Regular middleware has 3. That extra `err` parameter is what makes it special.
- If any route throws an error that isn't caught by a `try/catch` in the route itself, Express forwards it here
- It logs the error to the console (for debugging) and sends back a consistent JSON response: `{ error: "message" }` with status `500` (internal server error)
- The `_req` and `_next` prefixed with underscore — that's a convention meaning "I have to declare this parameter but I'm not using it." TypeScript would complain about unused variables otherwise.

Why it matters: Without this, an unhandled error would cause Express to send back an ugly HTML error page. This middleware ensures your API **always responds with JSON**, even when something unexpected breaks.

In `app.ts`, it's registered **last** with `app.use(errorHandler)` — that's important. Express runs middleware in order, so error handlers must come after all routes to catch their errors.

---

## Step 7: `src/app.ts`

This file **creates and configures the Express app**. It's the glue that wires everything together.

Line by line:

- **`const app = express()`** — creates a new Express application instance
- **`app.use(cors())`** — enables Cross-Origin Resource Sharing. Without this, a frontend running on a different domain (e.g., `localhost:5173`) would be blocked from calling your API (`localhost:3000`)
- **`app.use(express.json())`** — tells Express to automatically parse JSON request bodies. Without this, `req.body` would be `undefined` when someone sends JSON in a POST/PATCH request
- **`app.get("/health", ...)`** — a simple health check endpoint. Returns `{ status: "ok" }`. Useful for monitoring tools and Docker to verify the server is alive
- **`app.use("/api/tasks", taskRoutes)`** — mounts the task router at `/api/tasks`. So all the routes defined in `routes/tasks.ts` (like `GET /` and `POST /`) become `GET /api/tasks` and `POST /api/tasks`
- **`app.use(errorHandler)`** — registers the error handler last, as discussed in Step 6
- **`export default app`** — exports the app so both `server.ts` and the test files can import it

The key reason this is separate from `server.ts`: **tests import `app` directly** without starting a real HTTP server. Supertest wraps the app and makes requests in-memory.

### Q&A: "Express is a server? Then what is Node.js?"

**Node.js** is the **runtime** — it lets you run JavaScript outside the browser. On its own, Node.js *can* handle HTTP requests, but the code to do so is verbose and manual (parsing URLs, handling methods, sending responses yourself).

**Express** is a **framework** that runs on top of Node.js. It makes building web servers much easier by giving you things like routing (`GET /api/tasks`), middleware, JSON parsing, etc.

Think of it this way:
- **Node.js** = the engine (like a car engine)
- **Express** = the car built around that engine (steering wheel, seats, dashboard)

You *could* drive with just the engine, but Express makes it practical and comfortable.

### Q&A: "The interfaces are implemented in which language?"

The interfaces are written in **TypeScript** — a superset of JavaScript that adds types.

Interfaces like `Task`, `CreateTaskInput`, and `UpdateTaskInput` are a TypeScript-only feature. They define what shape an object must have at **compile time** — helping you catch mistakes before the code even runs.

Important: **interfaces don't exist at runtime**. When TypeScript compiles to JavaScript (the `npm run build` step), all interfaces are stripped out. They're purely a development tool for catching bugs early. That's why the `tsconfig.json` exists — it controls how TypeScript gets compiled down to regular JavaScript that Node.js can actually run.

---

## Step 8: `src/server.ts`

The **entry point** — the file that actually starts your server. It's intentionally the smallest file in the project.

Line by line:

- **`import app from "./app"`** — grabs the fully configured Express app
- **`const PORT = process.env.PORT || 3000`** — reads the port from an environment variable. If none is set, defaults to `3000`. This is important for deployment — platforms like Docker or cloud services set `PORT` for you
- **`app.listen(PORT, ...)`** — tells the app to start listening for HTTP requests on that port. The callback logs the URL so you know it's running

Why so small? Because its **only job is to start listening**. All the configuration, routes, and middleware are in `app.ts`. This separation means:
- Tests import `app.ts` — no server starts, no port conflicts
- `server.ts` is only used when you actually want to run the app (`npm run dev` or `npm start`)

This file is also excluded from test coverage in `vitest.config.ts` — there's nothing meaningful to test here since it just calls `.listen()`.

---

## Step 9: Tests

There are two types of tests in this project, both using **Vitest** as the test runner.

### 9a: Unit Tests (`tests/unit/taskService.test.ts`)

These test the **service layer in isolation** — no HTTP, no server. Just calling functions directly.

Structure:

- **`beforeEach(() => clearAllTasks())`** — runs before every single test to reset the in-memory store. This ensures tests don't affect each other

- Tests are grouped by function using `describe` blocks:
  - `createTask` — does it create correctly? does it trim whitespace? does it reject empty titles?
  - `getAllTasks` — empty when nothing exists? returns all after creating?
  - `getTaskById` — finds existing? returns undefined for fake IDs?
  - `updateTask` — updates title? marks completed? throws for fake IDs?
  - `deleteTask` — deletes existing? returns false for fake IDs?

- **`expect()`** is the assertion — it checks that a value matches what you expect

These are **fast** because there's no HTTP overhead. Just pure function calls.

### 9b: Integration Tests (`tests/integration/tasks.test.ts`)

These test the **full stack** — HTTP request goes through routes, middleware, and services together.

- Uses **Supertest** — a library that wraps your Express app and lets you make HTTP requests without starting a real server
- **`request(app).get("/api/tasks")`** — simulates a real GET request
- Tests verify both the **response body** and **status codes** (201 for created, 204 for deleted, 400 for bad input, 404 for not found)

### Unit vs Integration — why both?

- **Unit tests** catch bugs in your logic quickly
- **Integration tests** catch bugs in how pieces work together (wrong status code, bad JSON shape, middleware not running)

---

## Step 10: Docker (`Dockerfile` and `docker-compose.yml`)

### What is Docker?

Docker creates **containers** — lightweight, isolated environments that bundle your app with everything it needs to run (OS, Node.js, dependencies, your code). Think of it like a shipping container: no matter what ship (server) carries it, the contents stay the same.

### `Dockerfile` — line by line

**Stage 1: Builder**

```dockerfile
FROM node:20-alpine AS builder
```
Starts from a base image — Alpine Linux with Node.js 20 pre-installed. The `AS builder` gives this stage a name so we can reference it later.

```dockerfile
WORKDIR /app
```
Sets the working directory inside the container. All commands after this run from `/app`.

```dockerfile
COPY package*.json ./
RUN npm ci
```
Copies `package.json` and `package-lock.json` first, then installs dependencies. This is done **before** copying source code on purpose — Docker caches layers. If your code changes but dependencies don't, Docker reuses the cached `npm ci` layer and skips reinstalling. Saves time on rebuilds.

```dockerfile
COPY tsconfig.json ./
COPY src/ ./src/
RUN npm run build
```
Now copies source code and compiles TypeScript to JavaScript in `dist/`.

**Stage 2: Production**

```dockerfile
FROM node:20-alpine
```
Starts **fresh** — a clean image. Nothing from stage 1 carries over unless explicitly copied.

```dockerfile
COPY package*.json ./
RUN npm ci --omit=dev
```
Installs **only production dependencies** (express, cors, uuid). No TypeScript, no Vitest, no ESLint. Keeps the image small.

```dockerfile
COPY --from=builder /app/dist ./dist
```
This is the multi-stage magic — reaches back into the `builder` stage and copies just the compiled JavaScript.

```dockerfile
ENV NODE_ENV=production
ENV PORT=3000
EXPOSE 3000
```
Sets environment variables. `EXPOSE 3000` is documentation — tells other developers and tools that this container listens on port 3000. It doesn't actually open the port by itself.

```dockerfile
CMD ["node", "dist/server.js"]
```
The command that runs when the container starts. Runs the compiled JavaScript directly with Node — no TypeScript compilation at runtime.

### `docker-compose.yml` — line by line

```yaml
services:
  app:
    build: .
```
Defines a service called `app`. `build: .` means "build the Dockerfile in the current directory."

```yaml
    ports:
      - "3000:3000"
```
Maps port 3000 on your machine to port 3000 inside the container. Format is `host:container`. Without this, the container runs but you can't reach it from your browser.

```yaml
    environment:
      - NODE_ENV=production
      - PORT=3000
```
Passes environment variables into the container. These override any defaults.

In a real app, you'd add more services here — like a database:
```yaml
services:
  app:
    ...
  db:
    image: postgres:16
    ...
```
That's the power of compose — define your entire stack in one file.

---

## Step 11: CI/CD (`.github/workflows/ci.yml`)

### What is CI/CD?

- **CI (Continuous Integration)** — automatically test and validate code on every change
- **CD (Continuous Deployment)** — automatically deploy after tests pass (not set up in this project yet — just CI)

### GitHub Actions

GitHub's built-in CI system. When you push code, GitHub spins up a virtual machine, runs your instructions, and reports pass/fail.

### `ci.yml` — line by line

```yaml
name: CI
```
The name shown in the GitHub Actions UI.

```yaml
on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
```
**Triggers** — when this pipeline runs. Two scenarios:
- Someone pushes directly to `main`
- Someone opens (or updates) a pull request targeting `main`

This means feature branches don't trigger CI on their own — only when you try to merge into `main`.

```yaml
jobs:
  test:
    runs-on: ubuntu-latest
```
Defines a job called `test`. It runs on a fresh **Ubuntu Linux** virtual machine provided by GitHub (free for public repos).

```yaml
    strategy:
      matrix:
        node-version: [18, 20, 22]
```
The **matrix** creates parallel jobs. GitHub spins up **3 separate VMs**, each with a different Node.js version. All 3 must pass. This catches version-specific bugs — for example, a Node 18 feature that was removed in Node 22.

```yaml
    steps:
      - uses: actions/checkout@v4
```
**Step 1:** Checks out your repository code onto the VM. Without this, the VM is empty.

```yaml
      - name: Use Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: "npm"
```
**Step 2:** Installs the specific Node.js version from the matrix. `cache: "npm"` caches `node_modules` between runs so future pipelines are faster.

```yaml
      - name: Install dependencies
        run: npm ci
```
**Step 3:** Installs dependencies. `npm ci` (not `npm install`) is used because it's stricter — it installs exactly what's in `package-lock.json`, ensuring reproducible builds.

```yaml
      - name: Run tests
        run: npm test
```
**Step 4:** Runs your unit and integration tests. If any test fails, the job fails and GitHub shows a red X on your commit/PR.

```yaml
      - name: Build
        run: npm run build
```
**Step 5:** Compiles TypeScript. This catches type errors that might not surface in tests — for example, a wrong type that doesn't cause a runtime failure but is still incorrect.

### What happens on failure?

- The commit or PR gets a **red X** on GitHub
- Team members can be configured to get email/Slack notifications
- On a PR, it **blocks merging** (if branch protection rules are enabled)

---

## Additional Config Files

### `vitest.config.ts`
Configures the test runner with V8 coverage, targeting `src/` files and excluding `server.ts` from coverage (since it just starts the server).

### `.env.example`
A template showing what environment variables the app expects. Developers copy this to `.env` and fill in their values. The actual `.env` is in `.gitignore` so secrets never get committed.

### `.gitignore`
Tells Git which files to skip — `node_modules/`, `dist/`, `.env`, etc.

---

## Architecture Summary

```
Request → Express (app.ts)
           → Middleware (cors, json parser)
           → Routes (routes/tasks.ts)      ← HTTP concerns
             → Services (services/taskService.ts)  ← Business logic
               → Models (models/task.ts)   ← Data shapes
           → Error Handler (middleware/errorHandler.ts)  ← Safety net
```

The layers only depend downward: routes call services, services use models. Never the reverse. This makes each layer independently testable and replaceable.
